{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIAL DATA\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.transforms as mtransforms\n",
    "import os\n",
    "\n",
    "PATH = os.getcwd()\n",
    "PATH_OUTPUT= PATH+\"/figures\"\n",
    "if not os.path.exists(PATH_OUTPUT):\n",
    "    os.makedirs(PATH_OUTPUT)\n",
    "    \n",
    "kk = {\"UU\":\"Uusimaa\"}\n",
    "for da in [\"UU\"]:    \n",
    "    path1= PATH+\"/data\"\n",
    "    conn = sqlite3.connect(path1 +\"/simulated_SPAFHY_\"+da+\"_INIT.db\")\n",
    "    c = conn.cursor()\n",
    "    CREATE_TABLE = 'SELECT u.*,  (select max(stratum.H_dom) From stratum where stratum.data_id = u.data_id) as H_dom,  (select max(stratum.D_gm)  From stratum where stratum.data_id = u.data_id)              as D_gm,  (select sum(stratum.N)     From stratum where stratum.data_id = u.data_id and D_gm >40) as N_where_D_gt_40, (select sum(stratum.N)     From stratum where stratum.data_id = u.data_id and D_gm <=40 and D_gm > 35) as N_where_D_gt_35_lt_40, (select sum(stratum.N)     From stratum where stratum.data_id = u.data_id and D_gm <=35 and D_gm > 30) as N_where_D_gt_30_lt_35, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm >40) as V_where_D_gt_40, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm <=40 and D_gm > 35) as V_where_D_gt_35_lt_40, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm <=35 and D_gm > 30) as V_where_D_gt_30_lt_35, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 5) as V_populus, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 6) as V_Alnus_incana, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 7) as V_Alnus_glutinosa, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 8) as V_o_coniferous, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 9) as V_o_decidious, (select sum(stratum.i_vm3) From stratum where stratum.data_id = u.data_id) as i_Vm3,  (select sum(age*v)/sum(v) from stratum where stratum.data_id = u.data_id) as AGE_vol, (select sum(age*ba)/sum(ba) from stratum where stratum.data_id = u.data_id) as AGE_ba,  l.data_date,  b.branch,  b.branch_desc,  b.branching_group,  0 as income,  0 as cash_flow,   0 as clearcut,  0 as Harvested_V_log,  0 as Harvested_V_pulp,   0 as Harvested_V,   0 as Biomass_ton, 0 as Harvested_V_pulp_under_bark, 0 as Harvested_V_log_under_bark, 0 as income_log,  0 as income_pulp, 0 as income_log_change,   0 as income_pulp_change,  0 as income_biomass,  0 as Biomass,  0 as THIN                        FROM comp_unit u, data_link l left outer join branch_desc b on l.branch = b.branch and l.id = b.id  WHERE u.data_id=l.data_id  ORDER BY u.id, l.branch, l.data_date' \n",
    "    stand = {kk[da]:pd.read_sql(CREATE_TABLE, conn)}\n",
    "        \n",
    "#INITIAL DATA\n",
    "\n",
    "siteX =[\"Uusimaa\"]\n",
    "first_data = stand['Uusimaa']\n",
    "\n",
    "fig, ax1= plt.subplots(1,figsize=(4,5))\n",
    "\n",
    "df = pd.DataFrame(first_data[first_data['SC'] == 1].groupby(pd.cut(first_data[first_data['SC'] == 1]['Age'],np.arange(0,140,10))).sum()['AREA'])/sum(first_data['AREA'])*100\n",
    "df['2'] = pd.DataFrame(first_data[first_data['SC'] >= 2].groupby(pd.cut(first_data[first_data['SC'] >= 2]['Age'],np.arange(0,140,10))).sum()['AREA'])/sum(first_data['AREA'])*100\n",
    "df['3'] = pd.DataFrame(first_data[first_data['SC'] >= 3].groupby(pd.cut(first_data[first_data['SC'] >= 3]['Age'],np.arange(0,140,10))).sum()['AREA'])/sum(first_data['AREA'])*100\n",
    "df['4'] = pd.DataFrame(first_data[first_data['SC'] >= 4].groupby(pd.cut(first_data[first_data['SC'] >= 4]['Age'],np.arange(0,140,10))).sum()['AREA'])/sum(first_data['AREA'])*100\n",
    "df['5'] = pd.DataFrame(first_data[first_data['SC'] >= 5].groupby(pd.cut(first_data[first_data['SC'] >= 5]['Age'],np.arange(0,140,10))).sum()['AREA'])/sum(first_data['AREA'])*100\n",
    "df['6'] = pd.DataFrame(first_data[first_data['SC'] >= 6].groupby(pd.cut(first_data[first_data['SC'] >= 6]['Age'],np.arange(0,140,10))).sum()['AREA'])/sum(first_data['AREA'])*100\n",
    "df = df.rename(columns= {\"AREA\":\"1\"})\n",
    "\n",
    "df.plot(kind = \"bar\",y = \"1\",edgecolor = \"black\",ax= ax1,label = \"Rhtkg\")\n",
    "df.plot(kind = \"bar\",y = \"2\",ax = ax1,color = \"C2\",edgecolor = \"black\",label = \"Mtkg I\")\n",
    "df.plot(kind = \"bar\",y = \"3\",ax = ax1,color = \"C3\",edgecolor = \"black\",label = \"Mtkg II\")\n",
    "df.plot(kind = \"bar\",y = \"4\",ax = ax1,color = \"C4\",edgecolor = \"black\",label = \"Ptkg I\")\n",
    "df.plot(kind = \"bar\",y = \"5\",ax = ax1,color = \"C5\",edgecolor = \"black\",label = \"Ptkg II\")\n",
    "df.plot(kind = \"bar\",y = \"6\",ax = ax1,color = \"C6\",edgecolor = \"black\",label = \"Vatkg\")    \n",
    "ax1.set_ylim(0,25)\n",
    "\n",
    "ax1.get_legend().remove()\n",
    "\n",
    "ax1.set_ylabel(\"Proportion (%)\")\n",
    "\n",
    "ax1.set_title(\"Southern\")\n",
    "\n",
    "trans = mtransforms.ScaledTranslation(-20/72,7/272,fig.dpi_scale_trans)\n",
    "#ax1.text(0,1.03,\"a)\",transform=ax1.transAxes+trans,fontsize = 12)\n",
    "\n",
    "ax1.legend(title='Site Class', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')\n",
    "plt.savefig(PATH_OUTPUT+\"/Initial_distribution.png\", bbox_inches=\"tight\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0326f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TRADEOFF AND MANAGEMENT\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.transforms as mtransforms\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "PATH = os.getcwd()\n",
    "PATH_OUTPUT= PATH+\"/figures\"\n",
    "if not os.path.exists(PATH_OUTPUT):\n",
    "    os.makedirs(PATH_OUTPUT)\n",
    "\n",
    "labels_TRADE = {'NPV':\"c)\",\"INC\":\"b)\",\"PEAT\":\"a)\"}\n",
    "\n",
    "areak = [\"Uusimaa\"]\n",
    "\n",
    "kk = {\"UU\":\"Uusimaa\"}\n",
    "for da in [\"UU\"]:    \n",
    "    path1= PATH+\"/data\"\n",
    "    conn = sqlite3.connect(path1 +\"/simulated_SPAFHY_\"+da+\"_INIT.db\")\n",
    "    c = conn.cursor()\n",
    "    CREATE_TABLE = 'SELECT u.*,  (select max(stratum.H_dom) From stratum where stratum.data_id = u.data_id) as H_dom,  (select max(stratum.D_gm)  From stratum where stratum.data_id = u.data_id) as D_gm,  (select sum(stratum.N) From stratum where stratum.data_id = u.data_id and D_gm >40) as N_where_D_gt_40, (select sum(stratum.N)     From stratum where stratum.data_id = u.data_id and D_gm <=40 and D_gm > 35) as N_where_D_gt_35_lt_40, (select sum(stratum.N)     From stratum where stratum.data_id = u.data_id and D_gm <=35 and D_gm > 30) as N_where_D_gt_30_lt_35, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm >40) as V_where_D_gt_40, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm <=40 and D_gm > 35) as V_where_D_gt_35_lt_40, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm <=35 and D_gm > 30) as V_where_D_gt_30_lt_35, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 5) as V_populus, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 6) as V_Alnus_incana, (select sum(stratum.V) From stratum where stratum.data_id = u.data_id and SP = 7) as V_Alnus_glutinosa, (select sum(stratum.V) From stratum where stratum.data_id = u.data_id and SP = 8) as V_o_coniferous, (select sum(stratum.V) From stratum where stratum.data_id = u.data_id and SP = 9) as V_o_decidious, (select sum(stratum.i_vm3) From stratum where stratum.data_id = u.data_id) as i_Vm3,  (select sum(age*v)/sum(v) from stratum where stratum.data_id = u.data_id) as AGE_vol, (select sum(age*ba)/sum(ba) from stratum where stratum.data_id = u.data_id) as AGE_ba,  l.data_date,  b.branch,  b.branch_desc,  b.branching_group,  0 as income,  0 as cash_flow,   0 as clearcut,  0 as Harvested_V_log,  0 as Harvested_V_pulp,   0 as Harvested_V,   0 as Biomass_ton, 0 as Harvested_V_pulp_under_bark, 0 as Harvested_V_log_under_bark, 0 as income_log,  0 as income_pulp, 0 as income_log_change,   0 as income_pulp_change,  0 as income_biomass,  0 as Biomass, 0 as THIN FROM comp_unit u, data_link l left outer join branch_desc b on l.branch = b.branch and l.id = b.id  WHERE u.data_id=l.data_id  ORDER BY u.id, l.branch, l.data_date' \n",
    "    \n",
    "    stand = {kk[da]:pd.read_sql(CREATE_TABLE, conn)}\n",
    "    \n",
    "for siteX in areak:\n",
    "    for BM_GHG in [\"BM_GHG\"]:##Edit to include those options you have ran... ['BM_GHG','BM']\n",
    "        dat = pd.read_csv(PATH+\"/results/ALLNPV_DATA_2_NPVx\"+siteX+\"_DECS_\"+BM_GHG+\"_V1.csv\")\n",
    "        data = pd.read_pickle(PATH + \"/data/rslt_GWT_w_SPAFHY_PEAT_\"+siteX+\".pkl\",compression=\"bz2\")\n",
    "        data = data.reset_index().drop(['index'],axis=1)\n",
    "        data = data[data['id'].isin(set(dat['id']))]\n",
    "        dd1 = data[(~data['branching_group'].str.contains(\"Selection\"))]\n",
    "        dd2 = data[(data['branching_group'].str.contains(\"Selection\")) & (data['MAINT']!=\"MAINTENANCE\")]\n",
    "        data = pd.concat([dd1,dd2])\n",
    "\n",
    "        data = data[data['PEAT'] ==1]\n",
    "\n",
    "        data['branching_group'] = data['branching_group']+data[\"branch_desc\"]\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"+\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"-\",\"m\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\" \",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"_\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"_\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"|\",\"\")\n",
    "        data['branching_group'].replace({\"00\": \"SA\"}, inplace=True)\n",
    "        data.set_index([\"id\",\"branching_group\",\"year\"],inplace=True)\n",
    "\n",
    "        N2O_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"N2O\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "        CH4_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"CH4\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "        CO2_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"CO2\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "\n",
    "        area = data.loc[(slice(None),\"SA\",2016),'AREA'].sum()\n",
    "        for value in [\"PEAT\",\"NPV\",\"INC\"]:\n",
    "\n",
    "            fig, ax1 = plt.subplots(1,figsize=(18.2,23.7/3),dpi=300)\n",
    "            if value == \"NPV\":\n",
    "                XX, YY,ZZ  = \"PEAT_ha\",\"ALL_INC_ha\",\"ALL_NPV_ha\"\n",
    "                XXlab,YYlab,ZZlab =\"$\\Delta\\ t\\ CO_{2}$ eq. $ha^{-1}$\",\"Minimum yearly income, $€$ $ha^{-1}$ $year^{-1}$\",\"NPV @ 3% € $ha^{-1}$\"\n",
    "                if siteX == \"Uusimaa\":\n",
    "                    XS = 17\n",
    "                else:\n",
    "                    XS = 9\n",
    "            elif value == \"PEAT\":\n",
    "                XX, YY,ZZ  = \"ALL_NPV_ha\",\"ALL_INC_ha\",\"PEAT_ha\"\n",
    "                XXlab,YYlab,ZZlab =\"NPV @ 3% € $ha^{-1}$\",\"Minimum yearly income, $€$ $ha^{-1}$ $year^{-1}$\",\"$\\Delta\\ t\\ CO_{2}$ eq. $ha^{-1}$\"\n",
    "                XS = 6\n",
    "            elif value == \"INC\":\n",
    "                XX, YY,ZZ  = \"PEAT_ha\",\"ALL_NPV_ha\",\"ALL_INC_ha\"\n",
    "                XXlab,YYlab,ZZlab =\"$\\Delta\\ t\\ CO_{2}$ eq. $ha^{-1}$\",\"NPV @ 3% € $ha^{-1}$\",\"Minimum yearly income\\n $€$ $ha^{-1}$ $year^{-1}$\"\n",
    "                if siteX == \"Uusimaa\":\n",
    "                    XS = 17\n",
    "                else:\n",
    "                    XS = 14\n",
    "\n",
    "            test = pd.read_csv(PATH+\"/results/ALLNPV_DATA_2_\"+value+\"x\"+siteX+\"_\"+BM_GHG+\".csv\")\n",
    "            test['flow'] = [int(i/1000) for i in test[\"Unnamed: 0\"]]\n",
    "            kk = [i- int(i/1000)*1000 for i in test[\"Unnamed: 0\"]]\n",
    "\n",
    "            test['OBJ'] = kk\n",
    "\n",
    "            test[\"PEAT_ha\"] = 0.001*test['BM_CO2_INV']/area-0.001*test[\"PEAT_CO2\"]/area\n",
    "\n",
    "            test[\"ALL_NPV_ha\"] =test[\"ALL_NPV\"]/area\n",
    "            test[\"ALL_INC_ha\"] =(test[\"ALL_INC\"]/5)/area\n",
    "            test.set_index(['flow', 'OBJ'],inplace=True)\n",
    "\n",
    "            #normalize item number values to colormap\n",
    "            norm = matplotlib.colors.Normalize(vmin=0, vmax=22)\n",
    "\n",
    "            #colormap possible values = viridis, jet, spectral\n",
    "            for i in range(0,22):\n",
    "                rgba_color = cm.brg(norm(i),bytes=True) \n",
    "            ta=0\n",
    "            val = ((44/12)*.5*((data['BM_total'].loc[slice(None),\"SA\",2061]*data['AREA'].loc[slice(None),\"SA\",2061]).sum()-(stand[siteX]['BM_total']*stand[siteX]['AREA']).sum()))/(area*1000)-(N2O_MEAN.sum()*298+CH4_MEAN.sum()*25+CO2_MEAN.sum())/(area*1000)\n",
    "            for i in range(0,test.index.get_level_values(0).max()+1):\n",
    "                test.loc[i].plot(x = XX,y = YY, ax = ax1,color  = cm.brg(norm(i),bytes=False),label = str(int(test.loc[i][ZZ].min())))\n",
    "                if ta == 0:\n",
    "                    tt = {i:abs(test.loc[i]['PEAT_ha'].min()-val)}\n",
    "                else:\n",
    "                    tt[i] = abs(test.loc[i]['PEAT_ha'].min()-val)\n",
    "                ta = 1\n",
    "            if value == \"PEAT\":\n",
    "                P_VALUE = test.iloc[7]\n",
    "                if min(tt,key=tt.get) ==max(tt.keys()):\n",
    "                    part = (test.loc[min(tt,key=tt.get)-1][['ALL_NPV_ha','ALL_INC_ha']]-test.loc[min(tt,key=tt.get)][['ALL_NPV_ha','ALL_INC_ha']])/2+test.loc[min(tt,key=tt.get)][['ALL_NPV_ha','ALL_INC_ha']]\n",
    "\n",
    "                    ax1.plot(P_VALUE[XX],P_VALUE[YY],marker = \"*\",markersize = 18,markerfacecolor = \"red\",markeredgecolor=\"black\")\n",
    "                else:\n",
    "                    ax1.plot(P_VALUE[XX],P_VALUE[YY],marker = \"*\",markersize = 18,markerfacecolor = \"red\",markeredgecolor=\"black\")\n",
    "            else:\n",
    "                ax1.plot(P_VALUE[XX],P_VALUE[YY],marker = \"*\",markersize = 18,markerfacecolor = \"red\",markeredgecolor=\"black\")\n",
    "            while len(test.xs(XS,level=\"OBJ\")) != len(tt.keys()):\n",
    "                XS = XS +1\n",
    "            test.xs(XS,level=\"OBJ\").plot.scatter(x = XX,y = YY,ax=ax1,marker = \"x\",color = \"black\",s=16)\n",
    "            print(((44/12)*.5*((data['BM_total'].loc[slice(None),\"SA\",2061]*data['AREA'].loc[slice(None),\"SA\",2061]).sum()-(stand[siteX]['BM_total']*stand[siteX]['AREA']).sum()))/(area*1000)-(N2O_MEAN.sum()*298+CH4_MEAN.sum()*25+CO2_MEAN.sum())/(area*1000))\n",
    "            ax1.legend(title=ZZlab, labelspacing=0.3,bbox_to_anchor=(1, .95,0.0,0.05), loc='upper left',title_fontsize = 16,fontsize=14)#,mode= \"expand\")\n",
    "            ax1.set_ylabel(YYlab,fontsize = 19)\n",
    "            ax1.set_xlabel(XXlab,fontsize = 19)\n",
    "            ax1.tick_params(axis=\"x\",labelsize = 16)\n",
    "            ax1.tick_params(axis=\"y\",labelsize = 16)\n",
    "            print(str(test['PEAT_ha'].max()-P_VALUE['PEAT_ha'])+\" \"+siteX+ \" \"+ value +\" \"+str(test['PEAT_ha'].max())+\" \"+ str(P_VALUE['PEAT_ha']))\n",
    "\n",
    "            \n",
    "            #MANAGEMENT\n",
    "            Dec = pd.read_csv(PATH +\"/results/ALLNPV_DATA_2_\"+value+\"x\"+siteX+\"_DECS_\"+BM_GHG+\"_V1.csv\")\n",
    "            Dec[\"BG\"] = Dec['branching_group']\n",
    "\n",
    "            Dec.set_index(['id','BG'],inplace=True)\n",
    "            ii = 0\n",
    "\n",
    "            dataX = data[data['standid']>0]\n",
    "            dataX = dataX['AREA'].drop_duplicates().to_frame()\n",
    "\n",
    "            test1 = Dec#[test[\"ITER\"] == i]\n",
    "            d1  = dataX.merge(test1,left_index = True,right_index=True)\n",
    "\n",
    "            d1[\"AREA1\"] = d1['AREA']*d1['DEC']\n",
    "            (d1[((d1[\"DEC\"] >= 0) & (d1['branching_group'].str.contains(\"Selection\"))   & (~d1['branching_group'].str.contains(\"MAINTENANCE\")))]).groupby(\"ITER\")['AREA'].sum()\n",
    "            SA = (d1[((d1[\"DEC\"] >= 0) & (d1['branching_group'].str.contains(\"SA\"))   & (~d1['branching_group'].str.contains(\"MAINTENANCE\")))]).groupby(\"ITER\")['AREA1'].sum().to_frame().rename(columns={\"AREA1\":\"SA\"})\n",
    "            RF = (d1[((d1[\"DEC\"] >= 0) & (d1['branching_group'].str.contains(\"Normal\"))   & (~d1['branching_group'].str.contains(\"MAINTENANCE\")))]).groupby(\"ITER\")['AREA1'].sum().to_frame().rename(columns={\"AREA1\":\"RF\"})\n",
    "            RF_M = (d1[((d1[\"DEC\"] >= 0) & (d1['branching_group'].str.contains(\"Normal\"))   & (d1['branching_group'].str.contains(\"MAINTENANCE\")))]).groupby(\"ITER\")['AREA1'].sum().to_frame().rename(columns={\"AREA1\":\"RF_M\"})\n",
    "            CCF_M = (d1[((d1[\"DEC\"] >= 0) & (d1['branching_group'].str.contains(\"Selection\"))   & (d1['branching_group'].str.contains(\"MAINTENANCE\")))]).groupby(\"ITER\")['AREA1'].sum().to_frame().rename(columns={\"AREA1\":\"CCF_M\"})\n",
    "            CCF = (d1[((d1[\"DEC\"] >= 0) & (d1['branching_group'].str.contains(\"Selection\"))   & (~d1['branching_group'].str.contains(\"MAINTENANCE\")))]).groupby(\"ITER\")['AREA1'].sum().to_frame().rename(columns={\"AREA1\":\"CCF\"})\n",
    "            SA_M = (d1[((d1[\"DEC\"] >= 0) & (d1['branching_group'].str.contains(\"SA\"))   & (d1['branching_group'].str.contains(\"MAINTENANCE\")))]).groupby(\"ITER\")['AREA1'].sum().to_frame().rename(columns={\"AREA1\":\"SA_M\"})\n",
    "            ALL = pd.concat([RF_M,RF,CCF,SA],axis =1).fillna(0)\n",
    "\n",
    "            if value == \"PEAT\":\n",
    "                lf, bt,wd, hg = [0.16,0.65,0.15,0.2] #LOCATION of PLOT\n",
    "            else:\n",
    "                lf, bt,wd, hg = [0.16,0.22,0.15,0.2] #LOCATION of PLOT\n",
    "\n",
    "            ax2 = fig.add_axes([lf,bt,wd,hg])\n",
    "\n",
    "            color_dict = {'CCF': 'DarkOrange', 'SA': 'DarkGreen',\"RF\" : \"Red\",\"RF_M\" :\"Blue\"}\n",
    "            tx = list(test.xs(XS,level=\"OBJ\")['Unnamed: 0'])\n",
    "\n",
    "            ((100*ALL)/ALL.loc[0].sum()).loc[tx][['SA','RF','RF_M','CCF']].plot(kind=\"bar\",stacked=True,ax=ax2,rot=0,color = color_dict,width = .85)\n",
    "            ax2.legend(loc=\"lower center\",bbox_to_anchor=(0,-.5,1.,-.5),ncol=4,borderaxespad = 0,mode=\"expand\")\n",
    "            ax2.set_ylabel(\"Management proportion (%)\",fontsize = 10)\n",
    "            ax1.tick_params(axis=\"x\",labelsize = 12)\n",
    "            ax1.tick_params(axis=\"y\",labelsize = 12)\n",
    "\n",
    "            xx = 0\n",
    "\n",
    "            if len(((100*ALL)/ALL.loc[0].sum()).loc[tx][['SA','RF','RF_M','CCF']])== len([int(i) for i in test.groupby(level=[0]).min()[ZZ]]):\n",
    "                ax2.set_xticklabels([int(i) for i in test.groupby(level=[0]).min()[ZZ]])\n",
    "\n",
    "            if len(((100*ALL)/ALL.loc[0].sum()).loc[tx][['SA','RF','RF_M','CCF']])==20:\n",
    "                for label in ax2.xaxis.get_ticklabels()[::1]:\n",
    "                    if xx in [0,5,10,15,19]:\n",
    "                        y = 0\n",
    "                    else:\n",
    "                        label.set_visible(False)\n",
    "                    xx = xx+1\n",
    "            else:\n",
    "                for label in ax2.xaxis.get_ticklabels()[::1]:\n",
    "                    if xx in [0,5,10,15,20]:\n",
    "                        y = 0\n",
    "                    else:\n",
    "                        label.set_visible(False)\n",
    "                    xx = xx+1\n",
    "            if value == \"INC\":\n",
    "                ZZlab = \"Minimum yearly income, $€$ $ha^{-1}$ $year^{-1}$\"\n",
    "            ax2.set_xlabel(ZZlab,fontsize = 10)\n",
    "            ax2.set_ylim(0,100)\n",
    "            #ax2 fonts\n",
    "            \n",
    "            trans = mtransforms.ScaledTranslation(-20/72,7/272,fig.dpi_scale_trans)\n",
    "            ax1.text(-0.01,1.03,labels_TRADE[value],transform=ax1.transAxes+trans,fontsize = 20)\n",
    "            plt.savefig(PATH+\"/figures/LABELLED_\"+siteX+\"_\"+value+\"_\"+BM_GHG+\".png\", bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "            \n",
    "            fig, axb = plt.subplots(3,7,figsize=(4*5,3*4))\n",
    "            ii = 0\n",
    "            jj = 0\n",
    "            zz = 0\n",
    "            for i in set(test.index.get_level_values(0)):\n",
    "                xx=0\n",
    "                if jj == 7:\n",
    "                    ii =ii+1\n",
    "                    jj=0\n",
    "                tx = list(test.xs(i,level=\"OBJ\")['Unnamed: 0'])\n",
    "                ((100*ALL)/ALL.loc[0].sum()).loc[tx][['SA','RF','RF_M','CCF']].plot(kind=\"bar\",stacked=True,ax=axb[ii,jj],rot=0,color = color_dict,width = .85,legend=False)\n",
    "\n",
    "                axb[ii,jj].set_xticklabels([int(i) for i in (test[test['Unnamed: 0'].isin(((100*ALL)/ALL.loc[0].sum()).loc[tx].index)][ZZ])])\n",
    "                axb[ii,jj].set_xlabel(value)\n",
    "                axb[ii,jj].set_title(\"w = \" +str(round(1- (((100*ALL)/ALL.loc[0].sum()).loc[tx].iloc[0].name*0.05),2)))\n",
    "                if len(((100*ALL)/ALL.loc[0].sum()).loc[tx][['SA','RF','RF_M','CCF']])==20:\n",
    "                    for label in axb[ii,jj].xaxis.get_ticklabels()[::1]:\n",
    "                        if xx in [0,5,10,15,19]:\n",
    "                            y = 0\n",
    "                        else:\n",
    "                            label.set_visible(False)\n",
    "                        xx = xx+1\n",
    "                else:\n",
    "                    for label in axb[ii,jj].xaxis.get_ticklabels()[::1]:\n",
    "                        if xx in [0,5,10,15,20]:\n",
    "                            y = 0\n",
    "                        else:\n",
    "                            label.set_visible(False)\n",
    "                        xx = xx+1\n",
    "                jj = jj+1\n",
    "\n",
    "            for i in range(len(set(test.index.get_level_values(0))),21):\n",
    "                fig.delaxes(axb[ii,jj])\n",
    "                jj=jj+1\n",
    "            handels, labels = axb[0,0].get_legend_handles_labels()\n",
    "            fig.legend(handels,labels,loc=\"lower center\", ncol=4)\n",
    "            trans = mtransforms.ScaledTranslation(-20/72,7/272,fig.dpi_scale_trans)\n",
    "            axb[0,0].text(0,1.03,labels_TRADE[value],transform=axb[0,0].transAxes+trans,fontsize = 18)\n",
    "            fig.tight_layout()\n",
    "            plt.savefig(PATH+\"/figures/Management_\"+siteX+\"_\"+value+\"_\"+BM_GHG+\".png\", bbox_inches=\"tight\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812db0a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### HARVEST Figures\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "PATH = os.getcwd()\n",
    "PATH_OUTPUT= PATH+\"/figures\"\n",
    "if not os.path.exists(PATH_OUTPUT):\n",
    "    os.makedirs(PATH_OUTPUT)\n",
    "\n",
    "style = \"NPV\"\n",
    "labels_HARV = {'Uusimaa':[\"a)\",\"b)\"]}\n",
    "areak= [\"Uusimaa\"]\n",
    "\n",
    "kk = {\"UU\":\"Uusimaa\"}\n",
    "for da in [\"UU\"]:    \n",
    "    path1= PATH + \"/data\"\n",
    "    conn = sqlite3.connect(path1 +\"/simulated_SPAFHY_\"+da+\"_INIT.db\")\n",
    "    c = conn.cursor()\n",
    "    CREATE_TABLE = 'SELECT u.*,  (select max(stratum.H_dom) From stratum where stratum.data_id = u.data_id) as H_dom,  (select max(stratum.D_gm)  From stratum where stratum.data_id = u.data_id)              as D_gm,  (select sum(stratum.N)     From stratum where stratum.data_id = u.data_id and D_gm >40) as N_where_D_gt_40, (select sum(stratum.N)     From stratum where stratum.data_id = u.data_id and D_gm <=40 and D_gm > 35) as N_where_D_gt_35_lt_40, (select sum(stratum.N)     From stratum where stratum.data_id = u.data_id and D_gm <=35 and D_gm > 30) as N_where_D_gt_30_lt_35, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm >40) as V_where_D_gt_40, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm <=40 and D_gm > 35) as V_where_D_gt_35_lt_40, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and D_gm <=35 and D_gm > 30) as V_where_D_gt_30_lt_35, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 5) as V_populus, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 6) as V_Alnus_incana, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 7) as V_Alnus_glutinosa, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 8) as V_o_coniferous, (select sum(stratum.V)     From stratum where stratum.data_id = u.data_id and SP = 9) as V_o_decidious, (select sum(stratum.i_vm3) From stratum where stratum.data_id = u.data_id) as i_Vm3,  (select sum(age*v)/sum(v) from stratum where stratum.data_id = u.data_id) as AGE_vol, (select sum(age*ba)/sum(ba) from stratum where stratum.data_id = u.data_id) as AGE_ba,  l.data_date,  b.branch,  b.branch_desc,  b.branching_group,  0 as income,  0 as cash_flow,   0 as clearcut,  0 as Harvested_V_log,  0 as Harvested_V_pulp,   0 as Harvested_V,   0 as Biomass_ton, 0 as Harvested_V_pulp_under_bark, 0 as Harvested_V_log_under_bark, 0 as income_log,  0 as income_pulp, 0 as income_log_change,   0 as income_pulp_change,  0 as income_biomass,  0 as Biomass,  0 as THIN                        FROM comp_unit u, data_link l left outer join branch_desc b on l.branch = b.branch and l.id = b.id  WHERE u.data_id=l.data_id  ORDER BY u.id, l.branch, l.data_date' \n",
    "    if da ==\"KS\":\n",
    "        stand = {kk[da]:pd.read_sql(CREATE_TABLE, conn)}\n",
    "    else:\n",
    "        stand[kk[da]]=pd.read_sql(CREATE_TABLE, conn)\n",
    "areak= [\"Uusimaa\"]\n",
    "for siteX in areak:\n",
    "    for BM_GHG in ['BM_GHG']:#[\"BM\",\"BM_GHG\"]:\n",
    "        if BM_GHG == \"BM\":\n",
    "            labels_HARV = {'Keski-Suomi':[\"c)\",\"d)\"],'Pohjois-Pohjanmaa':[\"e)\",\"f)\"],'Uusimaa':[\"a)\",\"b)\"]}\n",
    "        else:\n",
    "            labels_HARV = {'Keski-Suomi':[\"a)\",\"b)\"],'Pohjois-Pohjanmaa':[\"c)\",\"d)\"],'Uusimaa':[\"a)\",\"b)\"]}\n",
    "        \n",
    "        dat = pd.read_csv(PATH+\"/results/ALLNPV_DATA_2_NPVx\"+siteX+\"_DECS_\"+BM_GHG+\"_V1.csv\")\n",
    "        data = pd.read_pickle(PATH + \"/data/rslt_GWT_w_SPAFHY_PEAT_\"+siteX+\".pkl\",compression=\"bz2\")\n",
    "        data = data.reset_index().drop(['index'],axis=1)\n",
    "        data = data[data['id'].isin(set(dat['id']))]\n",
    "        dd1 = data[(~data['branching_group'].str.contains(\"Selection\"))]\n",
    "        dd2 = data[(data['branching_group'].str.contains(\"Selection\")) & (data['MAINT']!=\"MAINTENANCE\")]\n",
    "        data = pd.concat([dd1,dd2])\n",
    "\n",
    "        data = data[data['PEAT'] ==1]\n",
    "\n",
    "        data['branching_group'] = data['branching_group']+data[\"branch_desc\"]\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"+\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"-\",\"m\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\" \",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"_\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"_\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"|\",\"\")\n",
    "        data['branching_group'].replace({\"00\": \"SA\"}, inplace=True)\n",
    "        data.set_index([\"id\",\"branching_group\",\"year\"],inplace=True)\n",
    "        area = data.loc[(slice(None),\"SA\",2016),'AREA'].sum()\n",
    "\n",
    "        N2O_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"N2O\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "        CH4_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"CH4\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "        CO2_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"CO2\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "\n",
    "        test = pd.read_csv(PATH + \"/results/ALLNPV_DATA_2_\"+style+\"x\"+siteX+\"_\"+BM_GHG+\".csv\")\n",
    "\n",
    "        test['flow'] = [int(i/1000) for i in test[\"Unnamed: 0\"]]\n",
    "        kk = [i- int(i/1000)*1000 for i in test[\"Unnamed: 0\"]]\n",
    "        test['OBJ'] = kk\n",
    "        test[\"PEAT_HA\"] = 0.001*test[\"PEAT_CO2\"]/area\n",
    "        test[\"ALL_NPV_HA\"] =test[\"ALL_NPV\"]/area\n",
    "\n",
    "        test[\"HARV_X_HA\"] = (test['BM_CO2_INV'])/(area*1000)\n",
    "        test[\"BM_X_HA_ONE_NPV\"] = (test['BM_CO2_INV'])/(area*1000)\n",
    "\n",
    "        test[\"HARV_X_HA_ONE_NPV\"] =((44/12)*(.5)*(.430)*(test[\"HARV_X\"])/area)\n",
    "\n",
    "        test[\"ALL_INC_HA\"] =test[\"ALL_INC\"]/area\n",
    "        test.set_index(['flow', 'OBJ'],inplace=True)\n",
    "        \n",
    "        test2 = pd.read_csv(PATH + \"/results/ALLNPV_DATA_2_PEATx\"+siteX+\"_\"+BM_GHG+\".csv\")\n",
    "        \n",
    "        test2['flow'] = [int(i/1000) for i in test2[\"Unnamed: 0\"]]\n",
    "        kk = [i- int(i/1000)*1000 for i in test2[\"Unnamed: 0\"]]\n",
    "        test2['OBJ'] = kk\n",
    "        test2[\"PEAT_HA\"] = 0.001*test2[\"PEAT_CO2\"]/area\n",
    "        test2[\"ALL_NPV_HA\"] =test2[\"ALL_NPV\"]/area\n",
    "\n",
    "        test2[\"HARV_X_HA\"] = (test2['BM_CO2_INV'])/(area*1000)\n",
    "        test2[\"BM_X_HA_ONE_NPV\"] = (test2['BM_CO2_INV'])/(area*1000)\n",
    "\n",
    "        test2[\"HARV_X_HA_ONE_NPV\"] =((44/12)*(.5)*(.430)*(test2[\"HARV_X\"])/area)\n",
    "\n",
    "        test2[\"ALL_INC_HA\"] =test2[\"ALL_INC\"]/area\n",
    "        test2.set_index(['flow', 'OBJ'],inplace=True)\n",
    "        \n",
    "        P_VALUE = test2.iloc[7]\n",
    "        #normalize item number values to colormap\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=22)\n",
    "\n",
    "        #colormap possible values = viridis, jet, spectral\n",
    "        for i in range(0,22):\n",
    "            rgba_color = cm.brg(norm(i),bytes=True) \n",
    "\n",
    "        fig, (ax1,ax2) = plt.subplots(1,2,figsize=(4*3,3*2))\n",
    "\n",
    "        #colormap possible values = viridis, jet, spectral\n",
    "        for i in range(0,22):\n",
    "            rgba_color = cm.brg(norm(i),bytes=True) \n",
    "        for i in range(0,test.index.get_level_values(0).max()+1):\n",
    "            test.loc[i].plot.scatter(x = \"PEAT_HA\",y = \"HARV_X_HA\", ax = ax1,color  = cm.brg(norm(i),bytes=False),label = str(int(test.loc[i]['ALL_NPV_HA'].mean())),legend=False)\n",
    "\n",
    "        handles, labels = ax1.get_legend_handles_labels()\n",
    "        ax1.set_ylabel(\"Biomass growth  (as t $CO_{2}$ eq. $ha^{-1}$)\")\n",
    "        ax1.set_xlabel(\"$\\Delta\\ t\\ GHG \\ CO_{2}$ eq. $ha^{-1}$\")\n",
    "        \n",
    "        ax1.plot(P_VALUE[\"PEAT_HA\"],P_VALUE[\"HARV_X_HA\"],marker = \"*\",markersize = 16,markerfacecolor = \"red\",markeredgecolor=\"black\")\n",
    "        \n",
    "        for i in range(0,test.index.get_level_values(0).max()+1):\n",
    "            test.loc[i].plot.scatter(x = \"HARV_X_HA_ONE_NPV\",y = \"BM_X_HA_ONE_NPV\", ax = ax2,color  = cm.brg(norm(i),bytes=False),label = str(int(test.loc[i]['ALL_NPV_HA'].min())),legend=True)\n",
    "        ax2.set_ylabel(\"Biomass growth (as t $CO_{2}$ eq. $ha^{-1}$)\")\n",
    "        ax2.legend(title='NPV @ 3% $ha^{-1}$', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')\n",
    "        ax2.set_xlabel(\"Harvested timber (as t $CO_{2}$ eq. $ha^{-1}$)\")\n",
    "        handles, labels = ax2.get_legend_handles_labels()\n",
    "        ax2.legend(handles[::-1], labels[::-1], title='NPV @ 3% $ha^{-1}$',  bbox_to_anchor=(1.05, 1), loc='upper left', fontsize = 'small')\n",
    "        ax2.plot(P_VALUE[\"HARV_X_HA_ONE_NPV\"],P_VALUE[\"BM_X_HA_ONE_NPV\"],marker = \"*\",markersize = 16,markerfacecolor = \"red\",markeredgecolor=\"black\")\n",
    "        if BM_GHG == \"BM\":\n",
    "            y_lm = [min(test[\"BM_X_HA_ONE_NPV\"]),max(test[\"HARV_X_HA\"])]\n",
    "            x_lm = [min(test[\"PEAT_HA\"]), max(test[\"HARV_X_HA_ONE_NPV\"])]\n",
    "            ax1.set_ylim(y_lm[0]*0.98,y_lm[1]*1.02)\n",
    "            ax2.set_ylim(y_lm[0]*0.98,y_lm[1]*1.02)\n",
    "        if BM_GHG == \"GHG\":\n",
    "            y_lm[0] = min(test[\"BM_X_HA_ONE_NPV\"])\n",
    "        \n",
    "        ax1.text(0,1.03,labels_HARV[siteX][0],transform=ax1.transAxes+trans,fontsize = 16)\n",
    "        ax2.text(0,1.03,labels_HARV[siteX][1],transform=ax2.transAxes+trans,fontsize = 16)\n",
    "        plt.savefig(PATH + \"/figures/THREE\"+siteX+\"_harvest_\"+BM_GHG+\".png\", bbox_inches=\"tight\")\n",
    "        print((test['BM_X_HA_ONE_NPV']-test[\"PEAT_HA\"]).mean())\n",
    "        print((test['BM_X_HA_ONE_NPV']).mean())\n",
    "        print((test[\"PEAT_HA\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc80e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Supplementary materials\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from pylab import figure, text, scatter, show\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "PATH = os.getcwd()\n",
    "PATH_OUTPUT= PATH+\"/figures\"\n",
    "if not os.path.exists(PATH_OUTPUT):\n",
    "    os.makedirs(PATH_OUTPUT)\n",
    "\n",
    "labels_HARV = {'Uusimaa':[\"a)\"]}\n",
    "\n",
    "areak = [\"Uusimaa\"]\n",
    "\n",
    "for siteX in areak:\n",
    "    for BM_GHG in ['BM_GHG']:#,'BM']:\n",
    "        dat = pd.read_csv(PATH+\"/results/ALLNPV_DATA_2_NPVx\"+siteX+\"_DECS_\"+BM_GHG+\"_V1.csv\")\n",
    "        data = pd.read_pickle(PATH + \"/data/rslt_GWT_w_SPAFHY_PEAT_\"+siteX+\".pkl\",compression=\"bz2\")\n",
    "        data = data.reset_index().drop(['index'],axis=1)\n",
    "        data = data[data['id'].isin(set(dat['id']))]\n",
    "\n",
    "        dd1 = data[(~data['branching_group'].str.contains(\"Selection\"))]\n",
    "        dd2 = data[(data['branching_group'].str.contains(\"Selection\")) & (data['MAINT']!=\"MAINTENANCE\")]\n",
    "        data = pd.concat([dd1,dd2])\n",
    "\n",
    "        data = data[data['PEAT'] ==1]\n",
    "\n",
    "        data['branching_group'] = data['branching_group']+data[\"branch_desc\"]\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"+\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"-\",\"m\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\" \",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"_\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"_\",\"\")\n",
    "        data['branching_group'] = data['branching_group'].str.replace(\"|\",\"\")\n",
    "        data['branching_group'].replace({\"00\": \"SA\"}, inplace=True)\n",
    "        data.set_index([\"id\",\"branching_group\",\"year\"],inplace=True)\n",
    "        area = data.loc[(slice(None),\"SA\",2016),'AREA'].sum()\n",
    "        N2O_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"N2O\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "        CH4_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"CH4\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "        CO2_MEAN =data.loc[(slice(None),\"SA\",slice(None)),[\"CO2\"+str(i) for i in range(2000,2016)]].mean(axis=1)*50*data.loc[(slice(None),\"SA\",slice(None)),'AREA']\n",
    "\n",
    "        fig, (ax1, ax2,ax3,ax4) = plt.subplots(1,4,figsize=(18,6),linewidth=10,edgecolor =\"black\")\n",
    "        test = pd.read_csv(PATH +\"/results/ALLNPV_DATA_2_PEATx\"+siteX+\"_\"+BM_GHG+\".csv\")\n",
    "        test_2 = pd.read_csv(PATH +\"/results/ALLNPV_DATA_2_NPVx\"+siteX+\"_\"+BM_GHG+\".csv\")\n",
    "        test_3 = pd.read_csv(PATH +\"/results/ALLNPV_DATA_2_INCx\"+siteX+\"_\"+BM_GHG+\".csv\")\n",
    "        test4 = pd.concat([test.reset_index(drop = True),test_2.reset_index(drop = True),test_3.reset_index(drop = True)])\n",
    "        x = test4['CO2']/(area*1000)\n",
    "        y = (test4['N2O'])/(area)\n",
    "        z = (test4['CH4'])/(area*1000)\n",
    "\n",
    "        p = ax1.scatter(x, y, c=z, cmap = \"viridis\", alpha=0.5,s = 5)\n",
    "        fig.colorbar(p,label = \"t $CH_{4}$ $ha^{-1}$\", ax = ax1)\n",
    "        ax1.set_ylabel(\"kg $N_{2}O$ $ha^{-1}$\")\n",
    "        ax1.set_xlabel(\"t $CO_{2}$ $ha^{-1}$\")\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "        ax1.plot(x, m*x + b, color = \"Black\")\n",
    "        ax1.text(.01, .99,'$R^2$: ' + str(round(r2_score(y, m*x + b),3)),horizontalalignment='left', verticalalignment='top', transform = ax1.transAxes)\n",
    "\n",
    "        z = test4['CO2']/(area*1000)\n",
    "        x = (test4['N2O'])/(area)\n",
    "        y = (test4['CH4'])/(area*1000)\n",
    "\n",
    "        p = ax2.scatter(x, y, c=z, cmap = \"viridis\", alpha=0.5,s = 5)\n",
    "        fig.colorbar(p,label = \"t $CO_{2}$ $ha^{-1}$\", ax = ax2)\n",
    "        ax2.set_xlabel(\"$N_{2}O$ $ha^{-1}$\")\n",
    "        ax2.set_ylabel(\"t $CH_{4}$ $ha^{-1}$\")\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "        ax2.plot(x, m*x + b, color = \"Black\")\n",
    "        ax2.text(.99, .99,'$R^2$: ' + str(round(r2_score(y, m*x + b),3)),horizontalalignment='right', verticalalignment='top', transform = ax2.transAxes)\n",
    "\n",
    "        x = test4['CO2']/(area*1000)\n",
    "        z = (test4['N2O'])/(area)\n",
    "        y = (test4['CH4'])/(area*1000)\n",
    "\n",
    "        p = ax3.scatter(x, y, c=z, cmap = \"viridis\", alpha=0.5,s = 5)\n",
    "        fig.colorbar(p,label = \"$N_{2}O$ $ha^{-1}$\", ax = ax3)\n",
    "        ax3.set_xlabel(\"t $CO_{2}$ $ha^{-1}$\")\n",
    "        ax3.set_ylabel(\"t $CH_{4}$ $ha^{-1}$\")\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "        ax3.plot(x, m*x + b, color = \"Black\")\n",
    "        ax3.text(.99, .99,'$R^2$: ' + str(round(r2_score(y, m*x + b),3)),horizontalalignment='right', verticalalignment='top', transform = ax3.transAxes)\n",
    "        trans = mtransforms.ScaledTranslation(-20/72,7/272,fig.dpi_scale_trans)\n",
    "        ax1.text(0,1.03,labels_HARV[siteX][0],transform=ax1.transAxes+trans,fontsize = 16)\n",
    "\n",
    "        x = test4['CO2']/(area*1000)+ (test4['N2O']*265)/(area*1000)+ (test4['CH4']*28)/(area*1000)\n",
    "        y = test4['GWT']/(area*1000)\n",
    "        z = test4['BM_CO2_INV']/(area*1000)\n",
    "        p = ax4.scatter(x, y, c = z,cmap = 'viridis', s = 5)\n",
    "\n",
    "        ax4.set_ylabel(\"GWT (m) \")\n",
    "        ax4.set_xlabel(\"$\\Delta\\ t\\ GHG \\ CO_{2}$ eq. $ha^{-1}$\")\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "        ax4.plot(x, m*x + b, color = \"Black\")\n",
    "        fig.colorbar(p,label = \"Biomass growth (as t $CO_{2}$ eq. $ha^{-1}$)\", ax = ax4)\n",
    "        ax4.text(.99, .99,'$R^2$: ' + str(round(r2_score(y, m*x + b),3)),horizontalalignment='right', verticalalignment='top', transform = ax4.transAxes)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        plt.savefig(PATH +\"/figures/emissions_\"+siteX+\"_\"+BM_GHG+\".png\", bbox_inches=\"tight\",edgecolor=fig.get_edgecolor())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0380b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
